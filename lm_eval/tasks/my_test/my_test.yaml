task: my_test
dataset_path: json
dataset_kwargs:
  data_files: lm_eval\tasks\my_test\questions.jsonl
  
output_type: multiple_choice
training_split: train
test_split: train  # Using train as test split since that's what we have

doc_to_text: "Question: {{ question }}\nA. {{choices['text'][0]}}\nB. {{choices['text'][1]}}\nC. {{choices['text'][2]}}\nD. {{choices['text'][3]}}\nE. {{choices['text'][4]}}\nAnswer:"
doc_to_target: answerKey
doc_to_choice: ['A', 'B', 'C', 'D', 'E']

metric_list:
  - metric: acc
    aggregation: mean
    higher_is_better: true

metadata:
  version: 0.0.1